I’m an AI/ML engineer and founder focused on building the next layer of intelligence infrastructure, systems where speed, safety, and cognition meet.

My work bridges Rust-native performance with large-scale model architecture. I design inference pipelines, latency-adaptive schedulers, and LLM optimization frameworks that push models closer to real-time intelligence.

Before Rust, I worked primarily in Python, building ML pipelines for finance, and signal modeling. That foundation in data and systems design evolved into Tensorust, where I now focus on production-grade Rust tools for high-performance inference.

Featured Projects

Every Other Token – Rust-based LLM optimizer reducing inference latency by 48%.

LLM Affector – runtime controller for token generation and contextual flow.

Adaptive Task Scheduler - distributed orchestration layer for multi-model pipelines.

Mycelium-AI Platform – biological sensing + AI integration for environmental feedback loops.

Core Stack
Rust, Python, PyTorch, Hugging Face Transformers, Flask, FastAPI, Docker, Linux, PostgreSQL

Focus Areas
LLM infrastructure, inference optimization, cognitive systems, Rust AI tooling

I like systems that scale under pressure, and the people who help build them.
If you’re experimenting at the edge of AI infrastructure, I’d love to connect.

https://raw.githubusercontent.com/anuraghazra/github-readme-stats/master/api/index.js



mattbusel@gmail.com
linkedin.com/in/matthewbusel
medium.com/@mattbusel


