I‚Äôm an AI/ML engineer and founder focused on building the next layer of intelligence infrastructure, systems where speed, safety, and cognition meet.

My work bridges Rust-native performance with large-scale model architecture. I design inference pipelines, latency-adaptive schedulers, and LLM optimization frameworks that push models closer to real-time intelligence.

Before Rust, I worked primarily in Python, building ML pipelines for finance, signal modeling, and context-aware AGI prototypes. That foundation in data and systems design evolved into Tensorust, where I now focus on production-grade Rust tools for high-performance inference.

Featured Projects

Every Other Token ‚Äì Rust-based LLM optimizer reducing inference latency by 48%.

LLM Affector ‚Äì runtime controller for token generation and contextual flow.

Adaptive Task Scheduler - distributed orchestration layer for multi-model pipelines.

Mycelium-AI Platform ‚Äì biological sensing + AI integration for environmental feedback loops.

Core Stack
Rust, Python, PyTorch, Hugging Face Transformers, Flask, FastAPI, Docker, Linux, PostgreSQL

Focus Areas
LLM infrastructure, inference optimization, cognitive systems, Rust AI tooling

I like systems that scale under pressure, and the people who help build them.
If you‚Äôre experimenting at the edge of AI infrastructure, I‚Äôd love to connect.

üìß mattbusel@gmail.com
 | üåê linkedin.com/in/matthewbusel
 | ü¶Ä github.com/Mattbusel


